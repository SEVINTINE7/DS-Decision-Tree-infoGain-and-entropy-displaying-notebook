{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3758a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain calculation related functions\n",
    "\n",
    "def entropy (ins,total,ins2): # to calculate entropy\n",
    "    if ins != 0 and ins2 != 0:\n",
    "        final = -(ins/total)*m.log2(ins/total) - ((ins2)/total)*m.log2((ins2)/total)\n",
    "        return final\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getEntropy(onA,onU): # to get an output with probabilities\n",
    "    total = onA+onU\n",
    "    Values = {\n",
    "            \"Entropy\" : entropy(onA,total,onU),\n",
    "            \"Prob\" : total\n",
    "        }\n",
    "    return Values\n",
    "\n",
    "def gain(arr, feature, total, wholeEntropy, buyAcc, buyUnacc, entro_data):\n",
    "    specVal = 0\n",
    "    fields = ['Col_Name'] # storing Fields for the entropy dataset\n",
    "    values = [feature] # storing values(entropies) for the entropy dataset\n",
    "\n",
    "    for i in arr: \n",
    "        # calculating and returning the information gain for each column\n",
    "        entropy = getEntropy(buyAcc.count(i), buyUnacc.count(i))[\"Entropy\"]\n",
    "        # assigning the entropy value to the entropy variable\n",
    "        specVal += (getEntropy(buyAcc.count(i), buyUnacc.count(i))[\"Prob\"] / total) * entropy \n",
    "        # calculating the total of info gains\n",
    "        fields.append(str(i))\n",
    "        values.append(entropy)\n",
    "        \n",
    "    final = wholeEntropy - specVal\n",
    "    record = {}\n",
    "    for field, value in zip(fields, values):# making the record to append into the dataset\n",
    "        record[field] = value\n",
    "    entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
    "    \n",
    "    return final, entro_data\n",
    "\n",
    "gains = {\n",
    "            'Buying':[],\n",
    "            'Maintain':[],\n",
    "            'Doors':[],\n",
    "            'Persons':[],\n",
    "            'LuggageBoot':[],\n",
    "            'Safety':[],\n",
    "        }\n",
    "feature_cols = {\n",
    "        'Buying':[1,2,3,4],\n",
    "        'Maintain':[1,2,3,4],\n",
    "        'Doors':[2,3,4,5],\n",
    "        'Persons':[2,4,5],\n",
    "        'LuggageBoot':[1,2,3],\n",
    "        'Safety':[1,2,3]\n",
    "    }\n",
    "\n",
    "def whole(dataset , dataset2): # To get information gains for all columns in the dataset\n",
    "    df = dataset2.copy()\n",
    "    for i in feature_cols:\n",
    "        buyAcc = []\n",
    "        buyUnacc = []\n",
    "        for row in dataset['Class_Value'].index:\n",
    "            if (dataset['Class_Value'][row] == \"acc\"):\n",
    "                buyAcc.append(dataset[i][row])\n",
    "            else:\n",
    "                buyUnacc.append(dataset[i][row])\n",
    "        acc6 = []\n",
    "        unacc6 = []\n",
    "        for row in dataset['Class_Value'].index:\n",
    "            if (dataset['Class_Value'][row] == \"acc\"):\n",
    "                acc6.append(dataset['Class_Value'][row])\n",
    "            else:\n",
    "                unacc6.append(dataset['Class_Value'][row])\n",
    "        tempGain, df = gain(feature_cols[i],i,len(dataset.index),getEntropy(acc6.count(\"acc\"),unacc6.count(\"unacc\"))['Entropy'],buyAcc,buyUnacc,df)\n",
    "#         df['Info_gains'][] = tempGain\n",
    "        \n",
    "        gains[i] = tempGain\n",
    "    for h,j in zip(range(6), feature_cols):\n",
    "            df['Info_gains'][h] = gains[j]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad87694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_finder(dataset):\n",
    "    acc6 = []\n",
    "    unacc6 = []\n",
    "    for row in dataset['Class_Value'].index:\n",
    "        if (dataset['Class_Value'][row] == \"acc\"):\n",
    "        \n",
    "            acc6.append(dataset['Class_Value'][row])\n",
    "        \n",
    "        else:\n",
    "            unacc6.append(dataset['Class_Value'][row])\n",
    "    print(\"acc count\",acc6.count('acc'))\n",
    "    print(\"unacc count\",unacc6.count('unacc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818908dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nd\n",
    "import math as m\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5389a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buying</th>\n",
       "      <th>Maintain</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Persons</th>\n",
       "      <th>LuggageBoot</th>\n",
       "      <th>Safety</th>\n",
       "      <th>Class_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1594 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Buying  Maintain  Doors  Persons  LuggageBoot  Safety Class_Value\n",
       "0          1         1      2        2            1       1       unacc\n",
       "1          1         1      2        2            1       2       unacc\n",
       "2          1         1      2        2            1       3       unacc\n",
       "3          1         1      2        2            2       1       unacc\n",
       "4          1         1      2        2            2       2       unacc\n",
       "...      ...       ...    ...      ...          ...     ...         ...\n",
       "1589       4         4      5        4            3       1       unacc\n",
       "1590       4         4      5        5            1       1       unacc\n",
       "1591       4         4      5        5            1       2         acc\n",
       "1592       4         4      5        5            2       1       unacc\n",
       "1593       4         4      5        5            3       1       unacc\n",
       "\n",
       "[1594 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\COURSE METERIALS\\\\New folder\\\\2nd year 1st sem\\\\DS\\\\Jupyter Notebook\\\\Dataset.csv')\n",
    "data = data.drop('ID',axis=1) # Dropping the first column('ID')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d8af6146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = data[data['Safety'] == 3]\n",
    "len(rows.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "dedaac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows2 = rows[rows['Persons'] == 5]\n",
    "len(rows2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bd07b3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows3 = rows2[rows2['Maintain'] == 4]\n",
    "len(rows3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "975e0bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows4 = rows3[rows3['Doors'] == 2]\n",
    "len(rows4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a1e4f92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows5 = rows4[rows4['Doors'] == 2]\n",
    "len(rows5.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3276eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows6 = rows5[rows5['Doors'] == 2]\n",
    "len(rows6.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a8f27789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12\n",
       "Name: Maintain, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows4['Maintain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "536e406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entr = {  # this dataset was made for hold the entropy values for each value in each column\n",
    "        'Col_Name':[],\n",
    "        '1':[],\n",
    "        '2':[],\n",
    "        '3':[],                       \n",
    "        '4':[],                       \n",
    "        '5':[],\n",
    "        'Info_gains':[]\n",
    "    }\n",
    "entropy_data = pd.DataFrame(entr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "26e7d8aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  entro_data = entro_data.append(record, ignore_index=True)# append the record dict into the dataset\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10372\\2516859625.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Info_gains'][h] = gains[j]\n"
     ]
    }
   ],
   "source": [
    "entrop_dataset = whole(rows4, entropy_data) # calling the previously defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "20774f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------+----------+-----+-----+-----+--------------+\n",
      "|    | Col_Name    |          1 |        2 |   3 |   4 |   5 |   Info_gains |\n",
      "|----+-------------+------------+----------+-----+-----+-----+--------------|\n",
      "|  0 | Buying      |   0.918296 | 0.918296 |   0 |   0 | nan |     0.311278 |\n",
      "|  1 | Maintain    |   0        | 0        |   0 |   1 | nan |     0        |\n",
      "|  2 | Doors       | nan        | 1        |   0 |   0 |   0 |     0        |\n",
      "|  3 | Persons     | nan        | 0        | nan |   0 |   1 |     0        |\n",
      "|  4 | LuggageBoot |   0        | 0        |   0 | nan | nan |     1        |\n",
      "|  5 | Safety      |   0        | 0        |   1 | nan | nan |     0        |\n",
      "+----+-------------+------------+----------+-----+-----+-----+--------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(entrop_dataset, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5af4f040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "LuggageBoot\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for i in feature_cols:\n",
    "    if(gains[i] > max):\n",
    "        max = gains[i]\n",
    "        col = i\n",
    "    elif(gains[i] == 0):\n",
    "        leave = 1\n",
    "print(max)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fcc02c5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc count 22\n",
      "unacc count 4\n"
     ]
    }
   ],
   "source": [
    "leaf_finder(rows3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
